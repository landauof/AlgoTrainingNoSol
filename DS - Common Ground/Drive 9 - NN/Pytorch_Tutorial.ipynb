{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-9-Pf1IcYAV8"
   },
   "source": [
    "**Pytorch Tutorial**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T08:35:00.729102Z",
     "start_time": "2020-07-10T08:34:59.425604Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "IkvGRUCaeodt"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as pltrt\n",
    "import time\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "ChzhDpPPZwZ1"
   },
   "source": [
    "## Tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Udcl8tCgZ6B1"
   },
   "source": [
    "Tensors are the base data structures of PyTorch which are used for building different types of neural networks. They can be considered as the generalization of arrays and matrices; in other words, tensors are N-dimensional matrices or multidimensional arrays.\n",
    "\n",
    "PyTorch tensors are similar to NumPy’s n-dimensional arrays. But unlike ndarrays of numpy, these tensors can be stored on a GPU RAM as well as the CPU RAM, and than to be multiplied efficientlly on the small many cores of the GPU (this is not the case with NumPy arrays). This is a major advantage of using tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "34hjE_dnjuUE"
   },
   "source": [
    "###  Tensor Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "WVdMHgL5gsuy"
   },
   "source": [
    "Tensors can be created by using a list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:47.300264Z",
     "start_time": "2020-07-08T11:14:47.275921Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "5gbGK5BifniP",
    "outputId": "eedfcfb2-e389-4fa1-eb41-32286c0a23f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "hS2GJDPThBSg"
   },
   "source": [
    "You can specify the data type of the tensor by using the ``dtype`` argument,\n",
    "similarily to numpy, you can check the type of the tensor by using the ``dtype`` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:48.082509Z",
     "start_time": "2020-07-08T11:14:48.019712Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "hidden": true,
    "id": "EWP-mViIiNrI",
    "outputId": "587b25f3-561b-42d1-e2aa-403478d6964c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 2., 3.])\n",
      "torch.float32\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([1,2,3], dtype = torch.float32)\n",
    "print(x)\n",
    "print(x.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Hx3qL4M8n5eP"
   },
   "source": [
    "It's important to note here that one way to evaluate a GPU is by its TFLOPS - the capability of a processor to calculate one trillion floating-point operations per second. These operations rate usually refer to a 32bit floating point and abiously depends on the tensot type. operations on a 64bit floating point will be half the rate and so on."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "sjvJ5IaPkDl-"
   },
   "source": [
    "Let’s say we want a matrix of shape 3*3 having all zeros/ones. Take a moment to think – how can we do that using NumPy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:48.704096Z",
     "start_time": "2020-07-08T11:14:48.699428Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "hidden": true,
    "id": "yXOFNYdaj4Bd",
    "outputId": "b8a76cb4-e03c-406a-8a80-2070761598d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[1. 1. 1.]\n",
      " [1. 1. 1.]\n",
      " [1. 1. 1.]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((3,3))\n",
    "b = np.ones((3,3))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "DY3HOvAOkUjU"
   },
   "source": [
    "Similar to NumPy, PyTorch also has the zeros() and ones() function which takes the shape as input and returns a matrix of zeros or ones , respectively, of a specified shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:49.466791Z",
     "start_time": "2020-07-08T11:14:49.459668Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "hidden": true,
    "id": "NxZN_iT4j4FX",
    "outputId": "beb93051-b945-40ca-cf69-3595a2c4ef22"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.zeros((3,3))\n",
    "b = torch.ones((3,3))\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "d8Y-nSZAoqBF"
   },
   "source": [
    "The ``random.randn()`` function returns random numbers that follow a standard normal distribution. \n",
    "\n",
    "We can initialize a similar matrix of random numbers using PyTorch:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:50.196125Z",
     "start_time": "2020-07-08T11:14:50.179352Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "hidden": true,
    "id": "9syMOW-lj4I_",
    "outputId": "e384d584-ac9e-4f4f-ee3f-0614d28b066a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3439,  1.0207,  0.4682],\n",
      "        [-0.7046, -1.6358,  0.8648]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "vUMUuLeBDKfa"
   },
   "source": [
    "### Tensor Copying"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "GIej_VuCDP4Y"
   },
   "source": [
    "As you will see later in this chapter,\n",
    "most of the tensor operations create a view of the origin tensor.\n",
    "\n",
    "Since it is a room for errors you must notice when you need to create a copy of your origin tensor.\n",
    "\n",
    "Unlike numpy, in torch the syntax is a bit different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "4cOUs78lE5eb"
   },
   "source": [
    "The function `copy_` copies the tensor given as a parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:51.237501Z",
     "start_time": "2020-07-08T11:14:51.219531Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "hidden": true,
    "id": "PKPmKwwmCv2Q",
    "outputId": "1d2bf780-d0b1-4b50-b2d1-c4412d12cbf6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0031,  1.5390,  0.1507],\n",
      "        [ 0.1464,  0.4540, -1.6974],\n",
      "        [ 0.9994,  2.9649, -0.7882]]) \n",
      "\n",
      "tensor([[ 0.0031,  1.5390,  0.1507],\n",
      "        [ 0.1464,  0.4540, -1.6974],\n",
      "        [ 0.9994,  2.9649, -0.7882]]) \n",
      "\n",
      "tensor(10.) \n",
      "\n",
      "tensor(0.0031)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,3)\n",
    "print(a, \"\\n\")\n",
    "\n",
    "b = torch.empty(3,3)\n",
    "b.copy_(a)\n",
    "print(b, \"\\n\")\n",
    "\n",
    "a[0,0] = 10\n",
    "print(a[0,0], \"\\n\")\n",
    "print(b[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "7bqdJJQWGwcL"
   },
   "source": [
    "The function `clone` also copies a tensor.\n",
    "\n",
    "However, unlike `copy_`, this function is recorded in the computation graph. \n",
    "(As you will see later in this tutorial, it means that gradients propagating to the cloned tensor will propagate to the original tensor.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:51.866640Z",
     "start_time": "2020-07-08T11:14:51.859514Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "hidden": true,
    "id": "J41DL91zGJHl",
    "outputId": "1bb1663d-8bde-4e38-b42e-a58d5b299ff9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.7539,  1.5914,  0.4844],\n",
      "        [ 0.2603,  0.5689, -1.4147],\n",
      "        [ 0.7192, -0.7546, -0.0325]]) \n",
      "\n",
      "tensor([[-0.7539,  1.5914,  0.4844],\n",
      "        [ 0.2603,  0.5689, -1.4147],\n",
      "        [ 0.7192, -0.7546, -0.0325]]) \n",
      "\n",
      "tensor(10.) \n",
      "\n",
      "tensor(-0.7539)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,3)\n",
    "print(a, \"\\n\")\n",
    "\n",
    "b = torch.empty(3,3)\n",
    "b = a.clone()\n",
    "print(b, \"\\n\")\n",
    "\n",
    "a[0,0] = 10\n",
    "print(a[0,0], \"\\n\")\n",
    "print(b[0,0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "ZE0e6D-D0x9t"
   },
   "source": [
    "### Shaping and Reshaping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "okaAc0As07rF"
   },
   "source": [
    "You can get the shape of a tensor using the ``.size()`` method or just the `.shape` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:53.222916Z",
     "start_time": "2020-07-08T11:14:53.219489Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "hidden": true,
    "id": "X9Ou2RMu0yOO",
    "outputId": "619574a4-c8b0-4103-e992-6cb491224180"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3])\n",
      "torch.Size([2, 3])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "\n",
    "print(a.size())\n",
    "print(a.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "6zUy9uI22miZ"
   },
   "source": [
    "We can use the `.view()` function and pass the required shape as a parameter. \n",
    "\n",
    "It will return a tensor with the new shape. \n",
    "\n",
    "Pay attention that the returned tensor isn't a copy of the original tensor, it will share the underling data with the original tensor.\n",
    "\n",
    "Let’s try to convert the above tensor of shape (2,3) to a tensor of shape (6,1):\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:54.183180Z",
     "start_time": "2020-07-08T11:14:54.179301Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "hidden": true,
    "id": "xbEoYY0D2qPb",
    "outputId": "57aecae7-fd06-4b5d-c260-90a555f635dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.7586],\n",
      "        [-1.3641],\n",
      "        [ 0.8333],\n",
      "        [-1.1916],\n",
      "        [ 1.2126],\n",
      "        [ 1.2027]])\n",
      "torch.Size([6, 1])\n"
     ]
    }
   ],
   "source": [
    "b = a.view(6,1)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:54.342668Z",
     "start_time": "2020-07-08T11:14:54.339233Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "hidden": true,
    "id": "HP7r3aoC2qSS",
    "outputId": "9db33165-4703-44ea-b1a6-99b85b4e9c2e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 5.0000],\n",
      "        [-1.3641],\n",
      "        [ 0.8333],\n",
      "        [-1.1916],\n",
      "        [ 1.2126],\n",
      "        [ 1.2027]])\n"
     ]
    }
   ],
   "source": [
    "a[0][0]=5\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "rzEu5hhq3ELO"
   },
   "source": [
    "If you know you want, for example, 6 rows however, you want torch to conclude the number of columns, you should send -1 as the columns dim argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:14:58.705701Z",
     "start_time": "2020-07-08T11:14:58.699899Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 212
    },
    "colab_type": "code",
    "hidden": true,
    "id": "uIdpWk8R3dlD",
    "outputId": "056904e4-355a-438a-82b8-c2f01d1a346b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.5073, -1.0995, -1.3037, -1.8282,  2.6740, -0.6350, -1.0132, -1.3216,\n",
      "          2.1444, -0.9532,  0.4376, -0.9195],\n",
      "        [ 0.1018, -0.7428, -1.0972,  1.8049,  0.0564,  0.5623,  0.1919,  0.7953,\n",
      "         -1.0935, -0.5183,  2.3910, -1.6647],\n",
      "        [-0.9019, -0.7969,  1.6069, -2.2665,  0.6811,  1.0040, -2.0533,  0.4894,\n",
      "          0.2383,  0.0669,  0.1759,  0.2783],\n",
      "        [-0.3404,  0.6444,  1.9914,  0.5651,  0.3954, -0.6160, -0.1313, -0.3293,\n",
      "         -0.6568, -1.4952,  1.2793, -0.0084],\n",
      "        [ 0.7884,  0.3921,  2.1639, -0.8934,  0.4576, -0.0099,  1.9759,  0.7851,\n",
      "         -0.0321,  0.7753,  0.8659, -0.2436]])\n",
      "torch.Size([5, 12])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,4,5)\n",
    "b = a.view(-1,12)\n",
    "print(b)\n",
    "print(b.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "dl8K1RR2IAVh"
   },
   "source": [
    "If you have two twnsors with the same amount of elements and you want to make their shape the same you can pass one's shape as a parameter to the `view` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:18.905514Z",
     "start_time": "2020-07-08T11:15:18.900347Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "hidden": true,
    "id": "PD_ddmzuH3BL",
    "outputId": "67da7391-702a-4696-8ce8-7b52df525478"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([6, 10]) \n",
      "\n",
      "torch.Size([3, 4, 5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3,4,5)\n",
    "print(a.size())\n",
    "b = torch.randn(6, 10)\n",
    "print(b.size(), \"\\n\")\n",
    "\n",
    "b = b.view(a.size())\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "B6QZ5OaUIx4e"
   },
   "source": [
    "However, you can do it more elegantlly using the `view_as` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:26.585552Z",
     "start_time": "2020-07-08T11:15:26.580407Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "hidden": true,
    "id": "5VPj_AWvI-mT",
    "outputId": "00150d2d-0c24-432b-c278-08936244b0f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 3, 4])\n",
      "torch.Size([6, 10]) \n",
      "\n",
      "torch.Size([5, 3, 4])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(5,3,4)#(3,4,5)\n",
    "print(a.size())\n",
    "b = torch.randn(6, 10)\n",
    "print(b.size(), \"\\n\")\n",
    "\n",
    "b = b.view_as(a)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "4W2-j4da2-rJ"
   },
   "source": [
    "You can also use the `torch.reshape` method,\n",
    "however, pay attentaion that torch.reshape may return a copy or a view of the original tensor - `torch.reshape` method will try to share the memory of the returned tensor, but if that complicates things for the torch architecture torch will make a clone of it and will return a new reshaped tensor. Thus you can not count on that to return a view or a copy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "VkoyXPWYT5ek"
   },
   "source": [
    "In order to transpose a 2D tensor, you can use ``torch.t`` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:28.187315Z",
     "start_time": "2020-07-08T11:15:28.180426Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "hidden": true,
    "id": "_f8AKKPaT9Ou",
    "outputId": "68860042-3a7c-487e-ad89-acfa85ce212f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.2093,  1.9752,  2.9178],\n",
      "        [ 0.7124, -0.8789,  0.3876]])\n",
      "tensor a shape is torch.Size([2, 3]) \n",
      "\n",
      "tensor([[-3.2093,  0.7124],\n",
      "        [ 1.9752, -0.8789],\n",
      "        [ 2.9178,  0.3876]])\n",
      "the transpose of tensor a shape is torch.Size([3, 2]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "\n",
    "print(a)\n",
    "print(f\"tensor a shape is {a.shape} \\n\")\n",
    "\n",
    "a_t = torch.t(a)\n",
    "print(a_t)\n",
    "print(f\"the transpose of tensor a shape is {a_t.shape} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "-j1Y7aG1UH5J"
   },
   "source": [
    "Pay attention that 0-D and 1-D tensors are returned as is. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:30.504842Z",
     "start_time": "2020-07-08T11:15:30.500662Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "hidden": true,
    "id": "obxGtUGjUJGS",
    "outputId": "f6b0dd83-3679-4b30-92fb-05fddfe44067"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5]) \n",
      "\n",
      "torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(5)\n",
    "print(a.shape, \"\\n\")\n",
    "\n",
    "a_t = torch.t(a)\n",
    "print(a_t.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "ASK30QiE1Jh7"
   },
   "source": [
    "If you want to transpose a tensor with more than 2 dimensions, you can use the `permute` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:31.987359Z",
     "start_time": "2020-07-08T11:15:31.980467Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "hidden": true,
    "id": "TEB798Wf2uxu",
    "outputId": "302f3703-e96e-4b71-fed7-b5e471b2011f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4, 5])\n",
      "torch.Size([5, 3, 4])\n",
      "tensor(True)\n",
      "tensor(False)\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, 4, 5)\n",
    "print(a.size())\n",
    "b.copy_(a.permute(2, 0, 1))\n",
    "print(b.size())\n",
    "\n",
    "print(a[1,2,3] == b[3,1,2])\n",
    "print(a[1,2,3] == b[1,2,3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "OyY_of_VtjKr"
   },
   "source": [
    "### Mathematical Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "PQNGI21FuNrB"
   },
   "source": [
    "Let’s now see how we can do mathematical operations using PyTorch on tensors. So, first, let’s initialize two tensors:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:33.945139Z",
     "start_time": "2020-07-08T11:15:33.940236Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "hidden": true,
    "id": "Y8YW3fnztiq7",
    "outputId": "5a776bc3-fc3e-4c56-dbb8-285da9b21f80"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.8360, -0.9178,  2.0370],\n",
      "        [-1.7283, -1.0608, -0.2821]])\n",
      "tensor([[ 1.1907, -0.2632, -0.2102],\n",
      "        [ 0.9699,  1.0924, -0.3522]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(2,3)\n",
    "\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "xEJJRX5QvRm8"
   },
   "source": [
    "There are 3 different ways to perform mathematical operations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "aWOf2t7Evbzs"
   },
   "source": [
    "1. Well known  mathematical operators:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:35.727470Z",
     "start_time": "2020-07-08T11:15:35.700315Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "hidden": true,
    "id": "788AXVMbj4OU",
    "outputId": "a588a775-97f0-41b9-878e-28c1c4a7002f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3547, -1.1810,  1.8268],\n",
      "        [-0.7585,  0.0316, -0.6343]]) \n",
      "\n",
      "tensor([[ 2.0268,  0.6546, -2.2472],\n",
      "        [ 2.6982,  2.1532, -0.0702]]) \n",
      "\n",
      "tensor([[-0.9955,  0.2416, -0.4282],\n",
      "        [-1.6762, -1.1588,  0.0994]]) \n",
      "\n",
      "tensor([[-1.1821, -2.5310],\n",
      "        [-1.7194, -2.7357]]) \n",
      "\n",
      "tensor([[-1.4243,  0.2868, -0.1032],\n",
      "        [-0.5612, -1.0298,  1.2488]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "print(a+b, \"\\n\")       # equivalent to: torch.add(a, b)\n",
    "\n",
    "# subtraction\n",
    "print(b-a, \"\\n\")       # equivalent to: torch.sub(b, a)\n",
    "\n",
    "# elementwise multiplication\n",
    "print(a*b, \"\\n\")       # equivalent to: torch.mul(a, b)\n",
    "\n",
    "# dot product\n",
    "print(a@torch.t(b), \"\\n\")       # equivalent to: torch.dot(a, b)\n",
    "\n",
    "# division\n",
    "print(b/a, \"\\n\")       # equivalent to: torch.div(b, a)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "zZugTYV7xGC_"
   },
   "source": [
    "2. Torch methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:36.629526Z",
     "start_time": "2020-07-08T11:15:36.620061Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "hidden": true,
    "id": "FqzSCIVrj4T7",
    "outputId": "5b9a2dde-1c90-4345-8d57-06619ff2501e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3547, -1.1810,  1.8268],\n",
      "        [-0.7585,  0.0316, -0.6343]]) \n",
      "\n",
      "tensor([[ 2.0268,  0.6546, -2.2472],\n",
      "        [ 2.6982,  2.1532, -0.0702]]) \n",
      "\n",
      "tensor([[-0.9955,  0.2416, -0.4282],\n",
      "        [-1.6762, -1.1588,  0.0994]]) \n",
      "\n",
      "tensor([[-1.1821, -2.5310],\n",
      "        [-1.7194, -2.7357]]) \n",
      "\n",
      "tensor([[-1.4243,  0.2868, -0.1032],\n",
      "        [-0.5612, -1.0298,  1.2488]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "print(torch.add(a, b), \"\\n\")\n",
    "\n",
    "# subtraction\n",
    "print(torch.sub(b, a), \"\\n\")\n",
    "\n",
    "# elementwise multiplication\n",
    "print(torch.mul(a, b), \"\\n\")\n",
    "\n",
    "# dot product\n",
    "print(torch.mm(a, torch.t(b)), \"\\n\")\n",
    "\n",
    "# division\n",
    "print(torch.div(b, a), \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "shsKUNJ7yeAD"
   },
   "source": [
    "3. Torch inplace methods\n",
    "\n",
    "  The inplace methods functionality is the same as the regular methods shown above, accept that their reult is written to the object they were operated on.\n",
    "The inplace methods always followed by an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:37.544391Z",
     "start_time": "2020-07-08T11:15:37.539968Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "hidden": true,
    "id": "4cbKzQeXj4Sc",
    "outputId": "23496c9b-73f8-4e93-afd6-7d9301a67d16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.3547, -1.1810,  1.8268],\n",
      "        [-0.7585,  0.0316, -0.6343]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# addition\n",
    "a.add_(b)\n",
    "print(a, \"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "l0SU3KKV0gCn"
   },
   "source": [
    "### Concatenating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "mCbZnCFANYZu"
   },
   "source": [
    "Let’s say we have two tensors as shown below and we want to concatenate them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:41.545668Z",
     "start_time": "2020-07-08T11:15:41.540648Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "hidden": true,
    "id": "eZJ3PbNfM2ts",
    "outputId": "77cce4cd-de96-4b1b-cb6c-ba62a011110d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "tensor([[5, 6],\n",
      "        [7, 8]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4]])\n",
    "b = torch.tensor([[5,6],[7,8]])\n",
    "\n",
    "print(a, \"\\n\")\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:42.306010Z",
     "start_time": "2020-07-08T11:15:42.300539Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 87
    },
    "colab_type": "code",
    "hidden": true,
    "id": "lrG7ypNSONrb",
    "outputId": "9d5e8112-c291-4df1-829b-565bd2cda634"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4],\n",
       "        [5, 6],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating vertically\n",
    "torch.cat((a,b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "AO2QeXW8OMzo"
   },
   "source": [
    "As you can see, the second tensor has been stacked below the first tensor. We can concatenate the tensors horizontally as well by setting the dim parameter to 1:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:43.464561Z",
     "start_time": "2020-07-08T11:15:43.460452Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "hidden": true,
    "id": "wrcdmLMNONvX",
    "outputId": "cace553c-df40-4fa0-f3e5-739cebd0927c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 5, 6],\n",
       "        [3, 4, 7, 8]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# concatenating horizontally\n",
    "torch.cat((a,b),dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "_ylevJwi7IQS"
   },
   "source": [
    "### Accumulating Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "4DTk3ITq7NCr"
   },
   "source": [
    "The accumulating functions are mostly the same in torch tensors as in numpy arrays.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:44.824478Z",
     "start_time": "2020-07-08T11:15:44.820389Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "hidden": true,
    "id": "UrpBYCA77NKo",
    "outputId": "e4fbed66-69a6-4de2-e4cb-e7bf3abd5584"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2.],\n",
      "        [3., 4.]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tensor([[1,2],[3,4]], dtype=torch.float32)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:45.034991Z",
     "start_time": "2020-07-08T11:15:45.020392Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "mYIN_LJv7NNM",
    "outputId": "8b329c14-a4dc-4d8d-f748-7ff386671670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a.sum() = 10.0\n"
     ]
    }
   ],
   "source": [
    "a_sum = a.sum()\n",
    "print(f\"a.sum() = {a_sum}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "qtQqPjXm8BjJ"
   },
   "source": [
    "Similarily to numpy, you can specify the axis which you want to accumulate along: \n",
    "\n",
    "``axis=0`` for columns and ``axis=1`` for rows (as oppose to numpy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:46.184054Z",
     "start_time": "2020-07-08T11:15:46.180153Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "QOy3HRB28A4m",
    "outputId": "c7d7535a-9b9e-4c68-d073-ce7170521302"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3.])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the mean of each column in the tensor a:\n",
    "a.mean(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "p_NRl1wa8oOm"
   },
   "source": [
    "A very important function to use after you have done an accumulationg operation is the ``torch.item`` function.\n",
    "This function return a scalar from a tensor which contain only one item in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:47.183860Z",
     "start_time": "2020-07-08T11:15:47.180134Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "hidden": true,
    "id": "yCdHLI5E8oiR",
    "outputId": "2a68f94f-3a3f-4e0a-ded4-4035c858d6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1]]) \n",
      "\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor([[1]])\n",
    "print(x, \"\\n\")\n",
    "\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "SSZU5uiVJdHK"
   },
   "source": [
    "Unlike numpy, `torch.max` return both the maximal element in  a tensor and its index.\n",
    "\n",
    "Use `dim=1` to maximize over each row of the tensor columns and `dims=0` to maximize over each column of the tensor rows.\n",
    "\n",
    "Take a moment and think, why is it useful? Yoy will see in the upcoming chapters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:48.688491Z",
     "start_time": "2020-07-08T11:15:48.660434Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 123
    },
    "colab_type": "code",
    "hidden": true,
    "id": "NzTGGCYbJdUE",
    "outputId": "63aac89b-cc9d-4c25-b9b2-1488ebf77c65"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.9915, -1.2090,  0.5122,  0.8937,  0.0353],\n",
      "        [ 1.0674,  1.0776,  0.4393, -1.2444, -0.5916],\n",
      "        [-0.2660, -0.7268, -0.1183, -0.8859, -0.3968]]) \n",
      "\n",
      "tensor([ 0.9915,  1.0776, -0.1183])\n",
      "tensor([0, 1, 2])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,5)\n",
    "print(x, \"\\n\")\n",
    "\n",
    "value, index = torch.max(x, dim=1) \n",
    "print(value)\n",
    "print(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "_7-lvSU04P84"
   },
   "source": [
    "### Numpy Bridge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Dd1yfLYlaL2S"
   },
   "source": [
    "Converting a torch Tensor to a numpy array and vice versa is a breeze. The torch Tensor and numpy array will share their underlying memory locations, and changing one will change the other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:50.746673Z",
     "start_time": "2020-07-08T11:15:50.740444Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "hidden": true,
    "id": "m0FzZ-bRVixy",
    "outputId": "c877874c-7b5c-4468-fa5a-86c61b6e6dbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [3 4]] \n",
      "\n",
      "tensor([[1, 2],\n",
      "        [3, 4]])\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2],[3,4]])\n",
    "print(a, \"\\n\")\n",
    "\n",
    "tensor = torch.from_numpy(a)\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Kql-nhgs5f16"
   },
   "source": [
    "Pay attenation that the numpy array and the torch tensor share the same memory,\n",
    "if you change the numpy array you chang the tensor and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:51.984367Z",
     "start_time": "2020-07-08T11:15:51.980216Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "hidden": true,
    "id": "siljsQ_15uF2",
    "outputId": "6db949c8-1daa-44db-c7df-066bc4e043e8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[5, 2],\n",
      "        [3, 4]]) \n",
      "\n",
      "[[6 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "a[0,0] = 5\n",
    "print(tensor, \"\\n\")\n",
    "\n",
    "tensor[0,0] = 6\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:15:52.623301Z",
     "start_time": "2020-07-08T11:15:52.620310Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "hidden": true,
    "id": "Y2GkB-AoafXX",
    "outputId": "2fbc9ebc-4816-481b-d2ba-b916efbb291c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[6 2]\n",
      " [3 4]]\n"
     ]
    }
   ],
   "source": [
    "b = tensor.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "y0yYyIDi-DVy"
   },
   "source": [
    "## Autograd: Automatic Differentiation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "4xkgH6MiOs5g"
   },
   "source": [
    "Central to all neural networks in PyTorch is the ``autograd`` package. Let’s first briefly visit this.\n",
    "\n",
    "The autograd package provides automatic differentiation for all operations on Tensors. \n",
    "\n",
    "It is a define-by-run framework, which means that your backprop is defined by how your code is run, and that every single iteration can be different."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "_Dd2RLo3QRp2"
   },
   "source": [
    "``torch.Tensor``, which you saw above, is the central class of the package. \n",
    "\n",
    "If you set its attribute ``.requires_grad`` as ``True``, it starts to track all operations on it. \n",
    "\n",
    "When you finish your computation you can call ``.backward()`` and have all the gradients computed automatically. \n",
    "\n",
    "The gradient for this tensor will be accumulated into .grad attribute."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "f9RTTP0CTDFc"
   },
   "source": [
    "There’s one more class which is very important for the autograd implementation - a ``Function``.\n",
    "\n",
    "Tensor and Function are interconnected and build up an acyclic graph, that encodes a complete history of computation. Each tensor has a ``.grad_fn`` attribute that references to a Function that has created the Tensor (except for Tensors created by the user - their ``grad_fn`` is ``None``).\n",
    "\n",
    "If you want to compute the derivatives, you can call ``.backward()`` on a Tensor. If Tensor is a scalar (i.e. it holds a one element data), you don’t need to specify any arguments to ``backward()``, however if it has more elements, you need to specify a gradient argument that is a tensor of matching shape."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:16:18.187518Z",
     "start_time": "2020-07-08T11:16:18.181388Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "hidden": true,
    "id": "jNQhjE4y4xyd",
    "outputId": "f0b30a75-3ece-466f-ae90-2fd3ae51783c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:16:18.906913Z",
     "start_time": "2020-07-08T11:16:18.900913Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "colab_type": "code",
    "hidden": true,
    "id": "DIA4YePZ4x2S",
    "outputId": "f53dbf89-b515-49ef-9da1-c20318df0164"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>) \n",
      "\n",
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) \n",
      "\n",
      "tensor(27., grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x + 2\n",
    "print(y, \"\\n\")\n",
    "\n",
    "z = y * y * 3\n",
    "print(z, \"\\n\")\n",
    "\n",
    "out = z.mean()\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "_E-J1QQeUzRW"
   },
   "source": [
    "Let’s backprop now. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:17:52.569056Z",
     "start_time": "2020-07-08T11:17:52.542380Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "r85e9PXCSIiH"
   },
   "outputs": [],
   "source": [
    "out.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Fv7Iks0oVIcp"
   },
   "source": [
    "Print gradients d(out)/dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:17:53.506087Z",
     "start_time": "2020-07-08T11:17:53.502188Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "hidden": true,
    "id": "3HKyiBpdSIlN",
    "outputId": "a6e9a057-59df-4242-a7b1-75244fffb22a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "UR5AThjyWzrC"
   },
   "source": [
    "Calculating the gradients with respect to all of our parameters is time-consuming.\n",
    "\n",
    "Therefore, there are times when we don't want the gradients to be computed.\n",
    "\n",
    "There are 3 ways to stop the gradients calculations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "9oqjap_IXSNE"
   },
   "source": [
    "1. Updating the ``.requires_grad`` attribute as ``False``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:17:54.149475Z",
     "start_time": "2020-07-08T11:17:54.143134Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "hidden": true,
    "id": "xYciquXkSIgr",
    "outputId": "cf0ff6df-daaa-4fed-ccf6-cf2fc44aba94"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.4713, -0.6872,  1.2077], requires_grad=True)\n",
      "True \n",
      "\n",
      "tensor([-0.4713, -0.6872,  1.2077])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, requires_grad=True)\n",
    "print(a)\n",
    "print(a.requires_grad, \"\\n\")\n",
    "\n",
    "a.requires_grad_(False)\n",
    "\n",
    "print(a)\n",
    "print(a.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "DB6nqFYKX8f9"
   },
   "source": [
    "2. Call .detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:17:55.107713Z",
     "start_time": "2020-07-08T11:17:55.102013Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "hidden": true,
    "id": "19A5z1J9SIaN",
    "outputId": "fb497e11-8d2a-428c-c464-b6ae6ed3ef3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.0438, -0.7316,  1.5778], requires_grad=True)\n",
      "True \n",
      "\n",
      "tensor([-1.0438, -0.7316,  1.5778])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, requires_grad=True)\n",
    "print(a)\n",
    "print(a.requires_grad, \"\\n\")\n",
    "\n",
    "b = a.detach()\n",
    "\n",
    "print(b)\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "RBVUsH9UY9ZR"
   },
   "source": [
    "Pay attention that the gradients above share the same memory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "QqqRo3Y0ZFXT"
   },
   "source": [
    "3. Using the ``with`` statement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:17:56.229011Z",
     "start_time": "2020-07-08T11:17:56.222472Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "hidden": true,
    "id": "ZH77Bg30ZFoi",
    "outputId": "4f0007db-7495-48c4-82ff-39117aa4809c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.6203, -0.7800, -0.6299], requires_grad=True)\n",
      "True \n",
      "\n",
      "tensor([1.3797, 1.2200, 1.3701])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(3, requires_grad=True)\n",
    "print(a)\n",
    "print(a.requires_grad, \"\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "  b = a+2\n",
    "  print(b)\n",
    "  print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "2Fj56RHmaQZ-"
   },
   "source": [
    "As mentioned earlier, the gradients are accumulated in the ``.grad``  attribute.\n",
    "\n",
    "Let's see an example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:00.908958Z",
     "start_time": "2020-07-08T11:18:00.902167Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 70
    },
    "colab_type": "code",
    "hidden": true,
    "id": "9PT-pzsbarhF",
    "outputId": "4aab472f-6cde-4afa-fea2-692562e82c36"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    \n",
    "    print(weights.grad)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "QzJBdvUKkcpU"
   },
   "source": [
    "That isn't what we want.\n",
    "\n",
    "We must zero the gradients before each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:01.187994Z",
     "start_time": "2020-07-08T11:18:01.182050Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "hidden": true,
    "id": "pN1DfRa8arkH",
    "outputId": "cfbc4531-4fcd-4cb8-80a2-981cb580b3c9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "  \n",
    "    print(weights.grad)\n",
    "\n",
    "    weights.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "maZnGuwo-bEu"
   },
   "source": [
    "##  Training Pipeline Overview: Model, Loss, and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "LqWvVHn4B2Tm"
   },
   "source": [
    "There are 3 common steps in order to make NN using pytorch.\n",
    "1. Design model (input, output, forward pass with different layers).\n",
    "2. Construct loss and optimizer.\n",
    "3. Training loop:\n",
    "      - Forward - compute prediction and loss.\n",
    "      - Backward - compute gradients.\n",
    "      - Update weights.\n",
    "\n",
    "Its important to understand the different components of the process and the well defined separation between them.\n",
    "- Forward - only needs the X features, and the current weights.\n",
    "- Backward - only needs the y label and the y_predicted to be given to the loss. So the gradients can be acumulated with respect to the loss (being calculated using ``loss.backprop()``).\n",
    "- Update weights - only needs the gradients and the optimizing method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "ZOMMiUS8-iTA"
   },
   "source": [
    "##  Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "PheQ9BoSoYvU"
   },
   "source": [
    "Here is our first very simple example of NN.\n",
    "\n",
    "This NN implements the simple linear regression.\n",
    "\n",
    "The most important thing to take from this example is the structure of our code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "PCRTjGO5pO_r"
   },
   "source": [
    "First, let's make a small dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:04.078105Z",
     "start_time": "2020-07-08T11:18:04.061910Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "cPSRp6zG_vk4"
   },
   "outputs": [],
   "source": [
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, \n",
    "                                            n_features=1, \n",
    "                                            noise=15, \n",
    "                                            random_state=42)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0], 1)\n",
    "\n",
    "n_samples, n_features = X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:04.920654Z",
     "start_time": "2020-07-08T11:18:04.701939Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "hidden": true,
    "id": "GCuQh5twsVqr",
    "outputId": "3a255c4e-d53b-4171-abad-abb6b43ce37f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(X , y)\n",
    "plt.title(\"Linear Regression Data\")\n",
    "plt.xlabel(\"X\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "avnbhCM8DQLH"
   },
   "source": [
    "Step No. 1:\n",
    "\n",
    "We define our NN as a class that inherite from ``nn.Module``.\n",
    "\n",
    "In this class we must implement two methods: the ``__init__`` method\n",
    "and the ``forward`` method.\n",
    "\n",
    "In the ``__init__`` method we firstly calling ``nn.Module`` ``__init__`` and then we define our NN layers, their input and outputs sizes.\n",
    "\n",
    "The  ``forward`` method performs the forward propagtion using the layers defined in the initialization. Most layers are already implemented for you in the ``nn`` module of pytorch. the first layer to be used is a ``nn.Linear`` layer, defined by its input dimenstions and output dimensions, storing the wights inside. In order to apply the layer one need just to pass an X to it as if it was a function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:06.625672Z",
     "start_time": "2020-07-08T11:18:06.621934Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "Y6x9Vt_nnsuE"
   },
   "outputs": [],
   "source": [
    "class LinearRegression(nn.Module):\n",
    "\n",
    "  def __init__(self, input_dim, output_dim):\n",
    "    super(LinearRegression, self).__init__()\n",
    "\n",
    "    self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "  def forward(self, x):\n",
    "    return self.lin(x)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:07.425783Z",
     "start_time": "2020-07-08T11:18:07.421748Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "hidden": true,
    "id": "L-xkf4Ywns2U",
    "outputId": "de6ad2d9-7a9e-44d2-ea00-7e0dcf1b7f52"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(\n",
       "  (lin): Linear(in_features=1, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LinearRegression(n_features, 1)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "0dZUiVhaav1k"
   },
   "source": [
    "Model class was made so it will contain layers that operate in a sequence. As such, a very convineint way to reffer to all parameters of all layers is the method ``.parameters()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:08.504147Z",
     "start_time": "2020-07-08T11:18:08.501726Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "rHubETGnsyBt"
   },
   "outputs": [],
   "source": [
    "w, b = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:09.201629Z",
     "start_time": "2020-07-08T11:18:09.021734Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "hidden": true,
    "id": "IHwacilQtrG7",
    "outputId": "2a63528f-0775-4e44-f43f-b041559e4719"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, w.item()*X+b.item(), c=\"r\")\n",
    "plt.scatter(X, y)\n",
    "plt.title(\"Initial Model\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Oe3E08-SGMAw"
   },
   "source": [
    "Step No 2.\n",
    "\n",
    "We define our loss function from ``torch.nn`` and our optimizer from ``torch.optim``. \n",
    "\n",
    "Notice that as ``nn.Linear``, a loss function is just another layer function operating on a layer output - simply with no weights stored inside. which puts it in the ``torch.nn`` module.\n",
    "\n",
    "Also notice how an optimizer needs to accept the parameters on which to optimize on. In the example above we chose to include all parameters off the model in the optimizing process. In other scenarios, For example in transfer learning, we would want to limit the parameters to be optimizing on just the last layers and not change the first layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:10.145305Z",
     "start_time": "2020-07-08T11:18:10.142023Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "2xuF6BgSns1M"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "loss = nn.MSELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "DLcVQdXEGom7"
   },
   "source": [
    "Step No 3.\n",
    "\n",
    "Here we perform our training loop.\n",
    "\n",
    "- forward propagation.\n",
    "- computing loss.\n",
    "- back propagation.\n",
    "- parameters update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:12.848334Z",
     "start_time": "2020-07-08T11:18:12.782259Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 357
    },
    "colab_type": "code",
    "hidden": true,
    "id": "0WbHgpHMrFHP",
    "outputId": "6f33969c-5770-4e0e-c4a0-4eff4823629d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch  10  loss =  1413.57958984375\n",
      "epoch  20  loss =  1063.767822265625\n",
      "epoch  30  loss =  813.8297729492188\n",
      "epoch  40  loss =  634.9125366210938\n",
      "epoch  50  loss =  506.60870361328125\n",
      "epoch  60  loss =  414.44952392578125\n",
      "epoch  70  loss =  348.151611328125\n",
      "epoch  80  loss =  300.3908996582031\n",
      "epoch  90  loss =  265.9395446777344\n",
      "epoch  100  loss =  241.0592803955078\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(n_iters):\n",
    "    # predict = forward pass with our model\n",
    "    y_predicted = model(X)\n",
    "\n",
    "    # loss\n",
    "    l = loss(y_predicted, y)\n",
    "\n",
    "    # calculate gradients = backward pass\n",
    "    l.backward()\n",
    "\n",
    "    # update weights\n",
    "    optimizer.step()\n",
    "\n",
    "    # zero the gradients after updating\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    if (epoch+1) % 10 == 0:\n",
    "        w, b = model.parameters()\n",
    "        print('epoch ', epoch+1,' loss = ', l.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:13.944751Z",
     "start_time": "2020-07-08T11:18:13.942024Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "6-HKQCRHrFKr"
   },
   "outputs": [],
   "source": [
    "w, b = model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T11:18:14.961994Z",
     "start_time": "2020-07-08T11:18:14.781589Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "hidden": true,
    "id": "6KJSWDh2rFNi",
    "outputId": "4e52f352-3354-48cf-f18a-0f36db9bf732"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'y')"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(X, w.item()*X+b.item(), c=\"r\")\n",
    "plt.scatter(X, y)\n",
    "plt.title(\"Final Model\")\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "-84Y2lymdYm0"
   },
   "source": [
    "Try running the training again and examine what happened. Do you expect that to happen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "c592nR1__vsZ"
   },
   "source": [
    "## ✍️  Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Vp61bcpnPGUj"
   },
   "source": [
    "In this section, you ware going to implement logistic regression using pytorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "cLqmXnU4N2j4"
   },
   "source": [
    "A short reminder of logistic regression:\n",
    "\n",
    "Let  $W$ be our parametrs matrix and $b$ our bias.\n",
    "\n",
    "The logistic function is defined by the following formula of the sigmoid function:\n",
    "\n",
    "$\\sigma(x; W,b) = \\frac{1}{1+e^{-(W\\cdot x+b)}}$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "KnCugy93ekzB"
   },
   "source": [
    "✍️ Step No. 0:\n",
    "\n",
    "Load the data and shape it so you can train a model on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:16:18.774383Z",
     "start_time": "2020-07-08T12:16:18.737356Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "qjCCelGB_104"
   },
   "outputs": [],
   "source": [
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "### ✍️ Split your data to train set and test set. Use 20% of your data as test.\n",
    "### START CODE HERE ### (1 line of code)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)\n",
    "### END CODE HERE ###\n",
    "\n",
    "\n",
    "### ✍️ Scale your data using the StandardScaler.\n",
    "### START CODE HERE ### (~3 lines of code)\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "### END CODE HERE ###\n",
    "\n",
    "### ✍️ Transform your data and labels to tensors. \n",
    "### Don't forget to convert their dtype to float32.\n",
    "### START CODE HERE ### (4 lines of code)\n",
    "X_train, y_train = torch.from_numpy(X_train).type(torch.float32), torch.from_numpy(y_train).type(torch.float32)\n",
    "X_test, y_test = torch.from_numpy(X_test).type(torch.float32), torch.from_numpy(y_test).type(torch.float32)\n",
    "### END CODE HERE ###\n",
    "\n",
    "### ✍️ Reshape your lables.\n",
    "### START CODE HERE ### (2 lines of code)\n",
    "\n",
    "# Why?\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "UBe0LDX_k-7V"
   },
   "source": [
    "✍️ Step No. 1:\n",
    "\n",
    "Define the LogisticRegression model. (read relevant layers in the nn documentaion)\n",
    "\n",
    "In the ``__init__`` method, define the layer and the activation.\n",
    "\n",
    "In the ``forward`` method, define forward propagartion.\n",
    "\n",
    "Finally, initiate a new LogisticRegression instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:16:19.141299Z",
     "start_time": "2020-07-08T12:16:19.135637Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "hidden": true,
    "id": "zBOujCq4kzWQ",
    "outputId": "11acf877-781d-4643-f890-04701c856d14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(\n",
      "  (linear): Linear(in_features=30, out_features=1, bias=True)\n",
      "  (sig): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        ### START CODE HERE ### (2 lines of code)\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "    def forward(self, x):\n",
    "        ### START CODE HERE ### (~1-3 lines of code)\n",
    "        out = self.linear(x)\n",
    "        out = self.sig(out)\n",
    "        return out\n",
    "        ### END CODE HERE ###\n",
    "\n",
    "### START CODE HERE ### (1 line of code)\n",
    "model = LogisticRegression(n_features)\n",
    "### END CODE HERE ###\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "JTApwLFLsRHC"
   },
   "source": [
    "✍️ Step No 2.\n",
    "\n",
    "Now, we define our loss function as the binary cross-entropy loss,\n",
    "\n",
    "and stochastic gradient-descent as our optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:16:19.858780Z",
     "start_time": "2020-07-08T12:16:19.855581Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "ctCEZoq_mmgz"
   },
   "outputs": [],
   "source": [
    "num_epochs = 100\n",
    "learning_rate = 0.01\n",
    "\n",
    "### START CODE HERE ### (2 lines of code)\n",
    "loss = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "yYlGomS5tt7a"
   },
   "source": [
    "✍️ Step No 3.\n",
    "\n",
    "Now, we perform our training loop.\n",
    "\n",
    "- forward propagation.\n",
    "- computing loss.\n",
    "- back propagation.\n",
    "- parameters update."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:19:39.492854Z",
     "start_time": "2020-07-08T12:19:39.443670Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "hidden": true,
    "id": "VFz9m1-yYN1z",
    "outputId": "9941d9cf-27ed-40a0-ddb3-1704ed93e2e0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 10, loss=0.21745291352272034\n",
      "epoch: 20, loss=0.21006450057029724\n",
      "epoch: 30, loss=0.20350202918052673\n",
      "epoch: 40, loss=0.19762291014194489\n",
      "epoch: 50, loss=0.1923161894083023\n",
      "epoch: 60, loss=0.18749448657035828\n",
      "epoch: 70, loss=0.18308767676353455\n",
      "epoch: 80, loss=0.17903903126716614\n",
      "epoch: 90, loss=0.17530207335948944\n",
      "epoch: 100, loss=0.17183829843997955\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(num_epochs):\n",
    "\n",
    "  ### Forward pass\n",
    "  ### START CODE HERE ### (1 line of code)\n",
    "    y_pred = model(X_train)\n",
    "  ### END CODE HERE ###\n",
    "\n",
    "  ### Loss calculation\n",
    "  ### START CODE HERE ### (1 line of code)\n",
    "    curr_loss = loss(y_pred, y_train) # NOTE: preds should be first\n",
    "  ### END CODE HERE ###\n",
    "\n",
    "  ### Backward pass\n",
    "  ### START CODE HERE ### (3 lines of code)\n",
    "    curr_loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "  ### END CODE HERE ###\n",
    "\n",
    "  ### Print loss every 10 epochs\n",
    "    \n",
    "    if((epoch+1)%10 == 0):\n",
    "        print(f\"epoch: {epoch+1}, loss={curr_loss.item()}\")\n",
    "    \n",
    "  ### START CODE HERE ### (2 lines of code)\n",
    "\n",
    "  ### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "svP4MtRy0RAp"
   },
   "source": [
    "✍️ Finally, We must check how our model perforn on the test set.\n",
    "\n",
    "In this part we make a forward pass, however, we don't want the gradient to be calculated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:23:47.202612Z",
     "start_time": "2020-07-08T12:23:47.198145Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "hidden": true,
    "id": "RGGrV4aSYOP6",
    "outputId": "5b010a81-bc37-43ea-dc1b-6a74187ea2f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.9473684210526315\n"
     ]
    }
   ],
   "source": [
    "### Compute the test accuracy. \n",
    "### Use 0.5 as the classification border, samples with sigmoid result greater\n",
    "### or equal to 0.5 will be classified as class 1, \n",
    "### and all the others will be classifies as class 0.\n",
    "### START CODE HERE ### (~5 lines of code)\n",
    "from sklearn.metrics import accuracy_score\n",
    "with torch.no_grad():\n",
    "    y_preds = np.round(model(X_test)) # turn preds to ints\n",
    "    print(f\"accuracy: {accuracy_score(y_preds, y_test)}\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "9lWfOt4J_3Va"
   },
   "source": [
    "## Dataset and DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "C3RQHq5SHDyN"
   },
   "source": [
    "As You probably saw in Andrew's course,\n",
    "the gradient computation is not efficient for the whole data set.\n",
    "\n",
    "Therefore, we divide the dataset into small batches, and compute the gradient on each batch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "g3xcskOxHnP3"
   },
   "source": [
    "A short reminder about the defenitions regarding this part:\n",
    "- epoch - one forward and backward pass of ALL training samples.\n",
    "- batch_size - number of training samples used in one forward/backward pass.\n",
    "- number of iterations - number of passes, each pass (forward+backward) using #batch_size number of sampes.\n",
    "\n",
    "e.g : 100 samples, batch_size=20 -> 100/20=5 iterations for 1 epoch.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "NRjFq-LvTREl"
   },
   "source": [
    "As explained above it might be a good idea to an object representing a Dataset to so we can feed the model in training time.\n",
    "\n",
    "In order to implement such a Dataset, we will inherit the class ``Dataset`` of pytorch.\n",
    "\n",
    "We will implement the following methods: ``__init__``, ``__getitem__`` , and ``__len__``,\n",
    "\n",
    "using the scikit-learn wine dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:42:33.859199Z",
     "start_time": "2020-07-08T12:42:33.830346Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "qUn0SOxd_66l"
   },
   "outputs": [],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "        data = datasets.load_wine(return_X_y=True)\n",
    "        self.n_samples = len(data[1])\n",
    "\n",
    "        self.x_data = torch.from_numpy(data[0])\n",
    "        self.y_data = torch.from_numpy(data[1]) \n",
    "\n",
    "    # support indexing such that dataset[i] can be used to get i-th sample\n",
    "    def __getitem__(self, index):\n",
    "        return self.x_data[index], self.y_data[index]\n",
    "\n",
    "    # we can call len(dataset) to return the size\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "\n",
    "\n",
    "# create dataset\n",
    "dataset = WineDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "dfSBV-rXVYhD"
   },
   "source": [
    "Now, let's see that we can get the first sample:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:58:29.250388Z",
     "start_time": "2020-07-08T12:58:29.244940Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "hidden": true,
    "id": "ux3zQCxtVSg9",
    "outputId": "c3cf42ec-cb49-4bce-b2cd-606770d724d2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03], dtype=torch.float64) \n",
      " tensor(0)\n"
     ]
    }
   ],
   "source": [
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, \"\\n\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "Sx4xARqVVCsH"
   },
   "source": [
    "Once we defined our ``Dataset`` object we can use the already implemented ``DataLoader`` class wraping the ``Dataset`` object with batching skills and more.\n",
    "\n",
    "The main aim of the ``DataLoader`` is to provide us a convinient way to iterate through the batches of our dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:58:29.636698Z",
     "start_time": "2020-07-08T12:58:29.633667Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "tSsyXPuZVC4u"
   },
   "outputs": [],
   "source": [
    "data_loader = DataLoader(dataset=dataset,\n",
    "                          batch_size=5,\n",
    "                          shuffle=True,\n",
    "                          num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "ALJMBrR-bNRB"
   },
   "source": [
    "We have just defined our data loader,\n",
    "\n",
    "now, let's convert it to an iterator and look at one random sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:58:30.103748Z",
     "start_time": "2020-07-08T12:58:30.073498Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 289
    },
    "colab_type": "code",
    "hidden": true,
    "id": "0EyzOR5KVC7l",
    "outputId": "0326b29b-037c-41bc-f04d-ccf5fa9a0f08"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.3160e+01, 2.3600e+00, 2.6700e+00, 1.8600e+01, 1.0100e+02, 2.8000e+00,\n",
      "         3.2400e+00, 3.0000e-01, 2.8100e+00, 5.6800e+00, 1.0300e+00, 3.1700e+00,\n",
      "         1.1850e+03],\n",
      "        [1.2080e+01, 2.0800e+00, 1.7000e+00, 1.7500e+01, 9.7000e+01, 2.2300e+00,\n",
      "         2.1700e+00, 2.6000e-01, 1.4000e+00, 3.3000e+00, 1.2700e+00, 2.9600e+00,\n",
      "         7.1000e+02],\n",
      "        [1.2850e+01, 3.2700e+00, 2.5800e+00, 2.2000e+01, 1.0600e+02, 1.6500e+00,\n",
      "         6.0000e-01, 6.0000e-01, 9.6000e-01, 5.5800e+00, 8.7000e-01, 2.1100e+00,\n",
      "         5.7000e+02],\n",
      "        [1.4380e+01, 3.5900e+00, 2.2800e+00, 1.6000e+01, 1.0200e+02, 3.2500e+00,\n",
      "         3.1700e+00, 2.7000e-01, 2.1900e+00, 4.9000e+00, 1.0400e+00, 3.4400e+00,\n",
      "         1.0650e+03],\n",
      "        [1.2870e+01, 4.6100e+00, 2.4800e+00, 2.1500e+01, 8.6000e+01, 1.7000e+00,\n",
      "         6.5000e-01, 4.7000e-01, 8.6000e-01, 7.6500e+00, 5.4000e-01, 1.8600e+00,\n",
      "         6.2500e+02]], dtype=torch.float64) \n",
      " tensor([0, 1, 2, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(data_loader)\n",
    "data = dataiter.next()\n",
    "features, labels = data\n",
    "print(features, \"\\n\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "SA1zs4OyXikV"
   },
   "source": [
    "✍️ Iterate through the batches of the dataset.\n",
    "For each batch print how much samples it has from each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T12:58:31.236247Z",
     "start_time": "2020-07-08T12:58:31.173958Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "colab_type": "code",
    "hidden": true,
    "id": "EvjJQWFwXMQj",
    "outputId": "eb7de328-4cf9-4ec1-db81-2cf9eca620ca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In batch 0: class 0 : 2, class 1 : 1,  class 2 : 2\n",
      "In batch 1: class 0 : 1, class 1 : 2,  class 2 : 2\n",
      "In batch 2: class 0 : 3, class 1 : 1,  class 2 : 1\n",
      "In batch 3: class 0 : 2, class 1 : 1,  class 2 : 2\n",
      "In batch 4: class 0 : 2, class 1 : 2,  class 2 : 1\n",
      "In batch 5: class 0 : 1, class 1 : 3,  class 2 : 1\n",
      "In batch 6: class 0 : 2, class 1 : 3,  class 2 : 0\n",
      "In batch 7: class 0 : 2, class 1 : 2,  class 2 : 1\n",
      "In batch 8: class 0 : 2, class 1 : 2,  class 2 : 1\n",
      "In batch 9: class 0 : 1, class 1 : 4,  class 2 : 0\n",
      "In batch 10: class 0 : 4, class 1 : 0,  class 2 : 1\n",
      "In batch 11: class 0 : 1, class 1 : 3,  class 2 : 1\n",
      "In batch 12: class 0 : 0, class 1 : 2,  class 2 : 3\n",
      "In batch 13: class 0 : 2, class 1 : 1,  class 2 : 2\n",
      "In batch 14: class 0 : 4, class 1 : 1,  class 2 : 0\n",
      "In batch 15: class 0 : 1, class 1 : 3,  class 2 : 1\n",
      "In batch 16: class 0 : 3, class 1 : 1,  class 2 : 1\n",
      "In batch 17: class 0 : 3, class 1 : 0,  class 2 : 2\n",
      "In batch 18: class 0 : 2, class 1 : 2,  class 2 : 1\n",
      "In batch 19: class 0 : 2, class 1 : 3,  class 2 : 0\n",
      "In batch 20: class 0 : 0, class 1 : 3,  class 2 : 2\n",
      "In batch 21: class 0 : 0, class 1 : 2,  class 2 : 3\n",
      "In batch 22: class 0 : 0, class 1 : 3,  class 2 : 2\n",
      "In batch 23: class 0 : 3, class 1 : 1,  class 2 : 1\n",
      "In batch 24: class 0 : 2, class 1 : 3,  class 2 : 0\n",
      "In batch 25: class 0 : 0, class 1 : 3,  class 2 : 2\n",
      "In batch 26: class 0 : 1, class 1 : 2,  class 2 : 2\n",
      "In batch 27: class 0 : 2, class 1 : 1,  class 2 : 2\n",
      "In batch 28: class 0 : 0, class 1 : 2,  class 2 : 3\n",
      "In batch 29: class 0 : 0, class 1 : 4,  class 2 : 1\n",
      "In batch 30: class 0 : 1, class 1 : 2,  class 2 : 2\n",
      "In batch 31: class 0 : 2, class 1 : 3,  class 2 : 0\n",
      "In batch 32: class 0 : 3, class 1 : 2,  class 2 : 0\n",
      "In batch 33: class 0 : 2, class 1 : 0,  class 2 : 3\n",
      "In batch 34: class 0 : 1, class 1 : 2,  class 2 : 0\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (~5 lines of code)\n",
    "for i, (features, labels) in enumerate(dataiter):\n",
    "    bin_count = labels.bincount()\n",
    "    # the 'if else' are for cases of bathes with no occurances of a class\n",
    "    c_0, c_1, c_2 = bin_count[0], 0 if len(bin_count)==1 else bin_count[1], 0 if len(bin_count)==2 else bin_count[2]\n",
    "    print(f\"In batch {i}: class 0 : {c_0}, class 1 : {c_1},  class 2 : {c_2}\")\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "tMPdPmMDZMZH"
   },
   "source": [
    "This exercise purpose is to let you find on your own the best and most convinient way to write the ``for`` loop command that iterate througt the batches."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "heading_collapsed": true,
    "id": "rWwEpMST_7c6"
   },
   "source": [
    "## Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "dGJQsNAiE2u4"
   },
   "source": [
    "Transforms can be applied to PIL images, tensors, ndarrays, or custom data\n",
    "during creation of the DataSet.\n",
    "\n",
    "You can find the complete list of built-in transforms here: \n",
    "https://pytorch.org/docs/stable/torchvision/transforms.html\n",
    "\n",
    "Usually, transformers are sent while initializing the dataset as an optional paramrter.\n",
    "Then the transform, if it exists, is being operated in the ``__getitem__`` method. \n",
    "\n",
    "In this way one can use transformers to delay some pre-process to realtime or make the pre-process depend on the batch itself. \n",
    "But mainly this is used to do augmentaions that varies with every iteration, and has an intrinsic randomness. We will see some examples in this chapter."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "DgBtHp2cE-aq"
   },
   "source": [
    "Some common transforms which you can find implemented in ``torchvision.transforms``:\n",
    "\n",
    "\n",
    "- On Images:\n",
    "\n",
    "> CenterCrop, Grayscale, Pad, RandomAffine, RandomCrop, RandomHorizontalFlip, RandomRotation, Resize, Scale.\n",
    "\n",
    "\n",
    "\n",
    "- On Tensors:\n",
    "\n",
    "> LinearTransformation, Normalize, RandomErasing.\n",
    "\n",
    "- Conversion:\n",
    "\n",
    "> ToPILImage: from tensor or ndrarray.\n",
    "\n",
    "> ToTensor : from numpy.ndarray or PILImage.\n",
    "\n",
    "- Custom:\n",
    "\n",
    "> Write your own class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T13:28:27.218576Z",
     "start_time": "2020-07-08T13:28:27.212864Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "qpglC4AHbrvW"
   },
   "outputs": [],
   "source": [
    "class LinearData(Dataset):\n",
    "  \n",
    "  def __init__(self, n_samples=100, transform=None):\n",
    "    X,y = datasets.make_regression(n_samples=n_samples,\n",
    "                                   n_features=1,\n",
    "                                   noise=15,\n",
    "                                   random_state=42)   \n",
    "    self.x = X\n",
    "    self.y = y.reshape((n_samples, -1))\n",
    "    self.n_samples = n_samples\n",
    "    self.transform = transform\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    sample = self.x[index], self.y[index]\n",
    "    if self.transform:\n",
    "      sample = self.transform(sample)\n",
    "    return sample\n",
    "\n",
    "  def __len__(self):\n",
    "    return self.n_samples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T13:28:27.335391Z",
     "start_time": "2020-07-08T13:28:27.332328Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "rDyIX-J6Nd1w"
   },
   "outputs": [],
   "source": [
    "class ToFloat32:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return inputs.astype(\"float32\"), targets.astype(\"float32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T13:28:27.659166Z",
     "start_time": "2020-07-08T13:28:27.652356Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "hidden": true,
    "id": "s-Kg-fdpPV4_",
    "outputId": "a69e3402-99b3-41a2-cf77-1bb241820b72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without transform:\n",
      "float64 float64 \n",
      "\n",
      "With transform to float32:\n",
      "float32 float32\n"
     ]
    }
   ],
   "source": [
    "print('Without transform:')\n",
    "dataset = LinearData(n_samples=500)\n",
    "features, labels = dataset[0]\n",
    "print(features.dtype, labels.dtype, \"\\n\")\n",
    "\n",
    "print('With transform to float32:')\n",
    "dataset = LinearData(n_samples=500, transform=ToFloat32())\n",
    "features, labels = dataset[0]\n",
    "print(features.dtype, labels.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "6zp1hiSkOz2s"
   },
   "source": [
    "✍️ Implement ToTensor transform.\n",
    "\n",
    "  Show that your transform works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T13:33:25.066072Z",
     "start_time": "2020-07-08T13:33:25.062558Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "1BscvwvbMbw2"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (~4 lines of code)\n",
    "class ToTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "### END CODE HERE ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T13:33:25.409822Z",
     "start_time": "2020-07-08T13:33:25.402070Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "hidden": true,
    "id": "uNBATEPxRsZe",
    "outputId": "af23603b-2b75-4113-b38b-b4e835b2cacc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Without transform:\n",
      "float64 float64 \n",
      "\n",
      "With transform to tensor:\n",
      "torch.float64 torch.float64\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (~8 lines of code)\n",
    "print('Without transform:')\n",
    "dataset = LinearData(n_samples=500)\n",
    "features, labels = dataset[0]\n",
    "print(features.dtype, labels.dtype, \"\\n\")\n",
    "\n",
    "print('With transform to tensor:')\n",
    "dataset = LinearData(n_samples=500, transform=ToTensor())\n",
    "features, labels = dataset[0]\n",
    "print(features.dtype, labels.dtype)\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "UF7QvPTgUSBO"
   },
   "source": [
    "✍️ Implement MulTransform. This transformer have to get a factor and multiply the labels with this given factor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T13:33:28.737068Z",
     "start_time": "2020-07-08T13:33:28.733666Z"
    },
    "colab": {},
    "colab_type": "code",
    "hidden": true,
    "id": "pZoy8D8jtL55"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (~7 lines of code)\n",
    "class MulTransform:\n",
    "    def __init__(self, multiplier):\n",
    "        self.multiplier = multiplier\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return inputs, targets * self.multiplier\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "hidden": true,
    "id": "U4cjLfrBudsO"
   },
   "source": [
    "✍️ Now, after we have built 3 transformers, let's compose them.\n",
    "\n",
    "Using ``torchvision.transforms`` documentation, write code which compose the above transformers.\n",
    "\n",
    "Your transform have to convert a numpy array to tensor of type float32 and multiply the labels of the data by 4. Show your code works. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-08T13:47:22.525241Z",
     "start_time": "2020-07-08T13:47:22.242574Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 312
    },
    "colab_type": "code",
    "hidden": true,
    "id": "q5TSfEXzipM3",
    "outputId": "4d2d1b68-8a2e-42a0-9f2d-485567f9ab6b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Linear dataset')"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "### START CODE HERE ### (~12 lines of code)\n",
    "trans = torchvision.transforms.Compose([ToFloat32(),ToTensor(),MulTransform(4)])\n",
    "\n",
    "dataset = LinearData(n_samples=500, transform=[])\n",
    "xs, ys = [row[0].item() for row in dataset], [row[1].item() for row in dataset]\n",
    "plt.scatter(xs, ys, label = \"Original\")\n",
    "\n",
    "t_dataset = LinearData(n_samples=500, transform=trans)\n",
    "txs , tys = [row[0].item() for row in t_dataset], [row[1].item() for row in t_dataset]\n",
    "plt.scatter(txs, tys, label = \"Transformed\")\n",
    "\n",
    "plt.legend()\n",
    "plt.xlabel(\"x\")\n",
    "plt.ylabel(\"y\")\n",
    "plt.title(\"Linear dataset\")\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6PFQSPImABS5"
   },
   "source": [
    "## ✍️ Feed-Forward Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5BRD8u16Ilkw"
   },
   "source": [
    "In this chapter you will write your first nueral network on your own!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jCoAIHTZIwB4"
   },
   "source": [
    "In this task we will use the well known MNIST dataset. Remember that this is a multiclass classification problem! \n",
    "\n",
    "Our nueral network will have 1 hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kuyGTaAJKTpW"
   },
   "source": [
    "At first, let's define some hyper-parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T08:35:04.781555Z",
     "start_time": "2020-07-10T08:35:04.775107Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2TQRxHOieXbb",
    "outputId": "09a2e6b2-14c4-4ebd-dc05-5f942f2af485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "### Delete this cell with solutions!\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:10:02.759925Z",
     "start_time": "2020-07-10T10:10:02.756528Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pF4N-TlMvl5m"
   },
   "outputs": [],
   "source": [
    "input_size = 784 # 28x28\n",
    "hidden_size = 240 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "eps = 1.0 * 10 ** -8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gMz8FcVRKfaF"
   },
   "source": [
    "Now, we define our dataset and dataloader for both the train and test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:38:40.075962Z",
     "start_time": "2020-07-10T10:38:40.071926Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.from_numpy(train_dataset.targets[0])\n",
    "test_dataset.targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:32:03.783119Z",
     "start_time": "2020-07-13T07:32:03.049464Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 369,
     "referenced_widgets": [
      "13ee488ac87d4ca08ca65c52007b9a45",
      "13fb20cbc4ec498cb3647cb8bc5636e6",
      "db1a520d33ec492cafc7c4bef5ac0b4d",
      "e61e6d62807a4d98aa02ec9efce34385",
      "1a1a983a94054905bb11a17b63849a42",
      "7be10f41d44a494d9f7b505defdddecd",
      "c3f755f2031140a58703ca96f2aba0c1",
      "c622970aa21d4950a22211d471ab0c37",
      "c6526d53f38f4e18a2f05d10ed235b71",
      "1e316fe196364204a40b6086aa138042",
      "bf5a42a74d2649819101e76e175be5b0",
      "374216a3626e44b6aaa31635e7e4463f",
      "c6d6eb302b6641639f9e23d1c85e718b",
      "55b895b1eb4540b3b85657182e7b2d3d",
      "e7745844a9d74fd5a9f081921359e78d",
      "c719772f047d4b7dafc1d70a5d24b3f7",
      "058ddde9299f4ad48eb342d6c9ebf8e5",
      "df392a622edf4fddbc3a191df64e0716",
      "1948a4f92b834db3a2815fa21f42d09e",
      "563eee532e3c42a692c7982427b86b45",
      "c623591cb7a14d1eacaedf0e448d0dcb",
      "f7761dd859d44fbbb49e0e42ca1ee8a8",
      "e22d257c1f9f441c85ac955e45747e94",
      "3cf21db7920442a9b00e9fc29b080a7f",
      "c619812fdeb640809c699c56b87198f6",
      "612439a0c2a74fac89324226f1d7ff33",
      "ba16954260ee49d186433e63b60f3757",
      "905c9c03e2fb4e578b485676729e8a74",
      "8468b21b37584ea6a88794352c548154",
      "cb166b52b45f40188d4ff158ff1e9ff4",
      "f4aa2f9b38274399b79e1cde38002e5a",
      "dd1aadb71d6a4025aa1c3c5ef939a66e"
     ]
    },
    "colab_type": "code",
    "id": "4nIJqHPsvM5Q",
    "outputId": "6c9ec1e4-cb4f-451c-faed-ceb1e39311ec"
   },
   "outputs": [],
   "source": [
    "\n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                          transform=torchvision.transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "# Added for the ignite part\n",
    "train_dataset.data = train_dataset.data.reshape(-1, 28*28)\n",
    "# Need to create a 60000X10 array s.t. if original value is 3 then new value is [0,0,0,1,0,0,0,0,0,0]\n",
    "old_targets = train_dataset.targets\n",
    "train_dataset.targets = np.array([[0.0]*10 for _ in old_targets]) # NOTE: MNIST specific becausd assumes 10 classes\n",
    "for row_ind, val in enumerate(iter(old_targets)):\n",
    "    train_dataset.targets[row_ind][val.item()] = 1.0-eps # sub eps because 1 is out of range for entropy (TODO: why?)\n",
    "train_dataset.targets = torch.from_numpy(train_dataset.targets).type(torch.LongTensor)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=torchvision.transforms.ToTensor())\n",
    "# Added for the ignite part\n",
    "test_dataset.data = test_dataset.data.reshape(-1, 28*28)\n",
    "# Need to create a 60000X10 array s.t. if original value is 3 then new value is [0,0,0,1,0,0,0,0,0,0]\n",
    "old_test_targets = test_dataset.targets\n",
    "test_dataset.targets = np.array([[0.0]*10 for _ in old_test_targets]) # NOTE: MNIST specific becausd assumes 10 classes\n",
    "for row_ind, val in enumerate(iter(old_test_targets)):\n",
    "    test_dataset.targets[row_ind][val.item()] = 1.0#-eps # sub eps because 1 is out of range for entropy (TODO: why?)\n",
    "test_dataset.targets = torch.from_numpy(test_dataset.targets)#.type(torch.LongTensor)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,#MyDataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, #MyDataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:00:24.542733Z",
     "start_time": "2020-07-13T07:00:24.537987Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([7, 2, 1,  ..., 4, 5, 6])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.targets.shape\n",
    "# train_dataset.targets[0][0]\n",
    "test_dataset.targets.shape\n",
    "old_test_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ffhQDIHUKtS6"
   },
   "source": [
    "✍️ Define your nueral network class. Use ReLU as your activation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:03:05.931483Z",
     "start_time": "2020-07-10T10:03:05.926262Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "mN3Z5pljvdcH"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (~12 lines of code)\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.l1 = nn.Linear(input_size, hidden_size)\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        return out\n",
    "    \n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HQEJD-QGLJ_G"
   },
   "source": [
    "✍️ Initialize your model with the above hyper-parameters. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:03:15.111257Z",
     "start_time": "2020-07-10T10:03:15.106364Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "kMICh4D1FAqH",
    "outputId": "62856073-f345-43b2-d986-3419b1ab7fa3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralNet(\n",
      "  (l1): Linear(in_features=784, out_features=240, bias=True)\n",
      "  (l2): Linear(in_features=240, out_features=10, bias=True)\n",
      "  (relu): ReLU()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (~1 line of code)\n",
    "model = NeuralNet(input_size, hidden_size, num_classes=num_classes)\n",
    "print(model)\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "f_ODwLF6Lc8v"
   },
   "source": [
    "✍️ Define the loss (which one should you choose? check the documentation and read it deeply! Fix your model definition if needed.) and use SGD as your optimization algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T08:35:36.087669Z",
     "start_time": "2020-07-10T08:35:36.084851Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "r1_cW9A9FBxO"
   },
   "outputs": [],
   "source": [
    "### START CODE HERE ### (2 lines of code)\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "### END CODE HERE ###  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "c3CyAywlM-Ul"
   },
   "source": [
    "✍️ Write the training loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T10:06:46.791485Z",
     "start_time": "2020-07-10T10:06:46.766655Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "id": "tOfQgs7_FGkO",
    "outputId": "bebb1041-a014-41e2-9c2a-f579955ffdc4"
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "only one element tensors can be converted to Python scalars",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-97-9c649e7664ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtrain_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m         \u001b[0mX_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.111\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0mtuple\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mindex\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32mclass\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \"\"\"\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtargets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;31m# doing this so that it is consistent with all other datasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: only one element tensors can be converted to Python scalars"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "\n",
    "### START CODE HERE ### (~10 lines of code)\n",
    "for epoch in range(num_epochs):\n",
    "    train_iter = iter(train_loader)\n",
    "    for i, (X_train, y_train) in enumerate(train_iter):\n",
    "            X_train = X_train.reshape(-1, 28*28).to(device)\n",
    "        y_train = y_train.to(device)\n",
    "        y_pred = model(X_train)\n",
    "        curr_loss = loss(y_pred, y_train) # NOTE: preds should be first\n",
    "        curr_loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if((i+1)%100 == 0):\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}], Step[{i+1}/{len(train_iter)}], loss={curr_loss.item()}\")\n",
    "    \n",
    "### END CODE HERE ### \n",
    "\n",
    "end = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T12:53:52.073224Z",
     "start_time": "2020-07-09T12:53:52.068119Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6M2t9uLXTicx",
    "outputId": "3fbf8587-8fd1-4f0d-fd42-2e4bfca6f4f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training took 19.8429856300354 seconds.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training took {end-start} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xgLL8cXKNR4y"
   },
   "source": [
    "✍️ Test your model on the test data. \n",
    "\n",
    "Make sure you don't waste time computing things you don't need! \n",
    "\n",
    "What is your accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T12:53:53.057845Z",
     "start_time": "2020-07-09T12:53:52.075866Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "OnpRDSeDz4Qw",
    "outputId": "5f59373e-f40b-4b5c-ad65-22181b45d175"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "### START CODE HERE ### (~10 lines of code)\n",
    "with torch.no_grad():\n",
    "    full_preds = []\n",
    "    full_test = []\n",
    "    test_iter = iter(test_loader)\n",
    "    \n",
    "    for i, (X_test, y_test) in enumerate(test_iter):\n",
    "        X_test = X_test.reshape(-1, 28*28).to(device)\n",
    "        y_preds = model(X_test)\n",
    "        y_preds = [el.argmax() for el in y_preds.detach().numpy()] # turn preds to list of ints\n",
    "        \n",
    "        full_preds += y_preds\n",
    "        full_test += y_test\n",
    "        \n",
    "    print(f\"accuracy: {accuracy_score(y_preds, y_test)}\")\n",
    "### END CODE HERE ### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I Try New Things\n",
    "TODO:\n",
    "1. Implement data loader V\n",
    "2. Use ignite to build, train and evaluate a model\n",
    "3. Add Tensorboard (visualizations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-10T08:35:44.846173Z",
     "start_time": "2020-07-10T08:35:44.835486Z"
    }
   },
   "outputs": [],
   "source": [
    "# Implement data loader\n",
    "class MyDataLoader():\n",
    "    \n",
    "    def __init__(self, dataset, batch_size, shuffle):\n",
    "        self._curr_batch = -1\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        \n",
    "        if not self.shuffle:\n",
    "            xs_batched = torch.split(dataset.data, batch_size, dim=0)\n",
    "            ys_batched = torch.split(dataset.targets, batch_size, dim=0)\n",
    "        else:\n",
    "            # Random sample for batches\n",
    "            \n",
    "            idx_batched = [random.choices(range(len(train_dataset.targets)), \n",
    "                                          k=batch_size) for i in range(int(len(dataset.data)/batch_size))]\n",
    "            \n",
    "            xs_batched = [train_dataset.data[idx] for idx in idx_batched]\n",
    "            ys_batched = [train_dataset.targets[idx] for idx in idx_batched]\n",
    "            \n",
    "        # .unsqueeze(1) to add a dimention to have have the same shape as the real data (from torch's loader)\n",
    "        # .float because int/int->int and I want a float\n",
    "        # division for normalization\n",
    "        self.dataset = [((x.unsqueeze(1).float()-train_dataset.data.min())/(train_dataset.data.max()-\n",
    "                                                                            train_dataset.data.min()).item(),\n",
    "                         y) for x,y in zip(xs_batched, ys_batched)]\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "        \n",
    "    def __iter__(self):\n",
    "        return self #self.dataset#iter([numpy.array([i]) for i in range(10)])\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self._curr_batch >= len(self.dataset)-1:\n",
    "            self._curr_batch=0\n",
    "            raise StopIteration\n",
    "        else:\n",
    "            self._curr_batch += 1\n",
    "            return self.dataset[self._curr_batch]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:32:16.838050Z",
     "start_time": "2020-07-13T07:32:13.138245Z"
    }
   },
   "outputs": [],
   "source": [
    "my_train_loader = MyDataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "my_test_loader = MyDataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# other_train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=False)\n",
    "# my_it = iter(my_train_loader)\n",
    "# ot_it = iter(other_train_loader)\n",
    "# # Check for equal batches (When shuffle=True, the expected outcome is \"False\" so...)\n",
    "# for a,b in zip(my_it, ot_it):\n",
    "#     print((a[0]==b[0]).all())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:32:18.213676Z",
     "start_time": "2020-07-13T07:32:16.840231Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Loss: 0.00\n",
      "Epoch[1] Loss: 0.00\n",
      "Epoch[1] Loss: 0.00\n",
      "Epoch[1] Loss: 0.00\n",
      "Epoch[1] Loss: 0.00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Current run is terminating due to exception: For binary cases, y_pred must be comprised of 0's and 1's..\n",
      "Engine run is terminating due to exception: For binary cases, y_pred must be comprised of 0's and 1's..\n",
      "Engine run is terminating due to exception: For binary cases, y_pred must be comprised of 0's and 1's..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch[1] Loss: 0.00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "For binary cases, y_pred must be comprised of 0's and 1's.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-263-605ad6df1784>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmy_train_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    708\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed_time_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 710\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    711\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melapsed_time_message\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-263-605ad6df1784>\u001b[0m in \u001b[0;36mlog_validation_results\u001b[0;34m(trainer)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlog_validation_results\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmy_test_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, data, max_epochs, epoch_length, seed)\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_internal_run\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Engine run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    724\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataloader_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_internal_run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    695\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 697\u001b[0;31m                 \u001b[0mtime_taken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_once_on_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    698\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEPOCH_COMPLETED\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime_taken\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0mhours\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmins\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_to_hours_mins_secs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_taken\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    786\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Current run is terminating due to exception: %s.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 788\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_handle_exception\u001b[0;34m(self, e)\u001b[0m\n\u001b[1;32m    435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEXCEPTION_RAISED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 437\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    439\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_run_once_on_dataset\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    770\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_STARTED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    771\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 772\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEvents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mITERATION_COMPLETED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    773\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    774\u001b[0m                 \u001b[0;31m# TODO: remove refs on batch to avoid high mem consumption ? -> need verification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/engine/engine.py\u001b[0m in \u001b[0;36m_fire_event\u001b[0;34m(self, event_name, *event_args, **event_kwargs)\u001b[0m\n\u001b[1;32m    391\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                 \u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mothers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 393\u001b[0;31m                 \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfirst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevent_args\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mothers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfire_event\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevent_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/metrics/metric.py\u001b[0m in \u001b[0;36miteration_completed\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 )\n\u001b[1;32m    219\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_required_output_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompleted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mEngine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/metrics/metric.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    486\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 487\u001b[0;31m         \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    488\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_reduced\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/metrics/accuracy.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m    147\u001b[0m         \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/metrics/accuracy.py\u001b[0m in \u001b[0;36m_check_type\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0mupdate_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_binary_multilabel_cases\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m                 \u001b[0mupdate_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/metrics/accuracy.py\u001b[0m in \u001b[0;36m_check_binary_multilabel_cases\u001b[0;34m(self, output)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For binary cases, y_pred must be comprised of 0's and 1's.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: For binary cases, y_pred must be comprised of 0's and 1's."
     ]
    }
   ],
   "source": [
    "# Use Ignite\n",
    "from ignite.engine import Events, create_supervised_trainer, create_supervised_evaluator\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "\n",
    "model = torch.nn.Sequential(\n",
    "    nn.Linear(input_size,hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size,out_features=num_classes),\n",
    ")\n",
    "\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "trainer = create_supervised_trainer(model=model, optimizer=optimizer, loss_fn=loss)\n",
    "val_metrics = {\n",
    "    \"accuracy\": Accuracy(),\n",
    "    \"cel\": Loss(loss)\n",
    "}\n",
    "evaluator = create_supervised_evaluator(model, metrics=val_metrics)\n",
    "\n",
    "@trainer.on(Events.ITERATION_COMPLETED(every=100))\n",
    "def log_training_loss(trainer):\n",
    "    print(\"Epoch[{}] Loss: {:.2f}\".format(trainer.state.epoch, trainer.state.output))\n",
    "\n",
    "@trainer.on(Events.EPOCH_COMPLETED)\n",
    "def log_validation_results(trainer):\n",
    "    evaluator.run(my_test_loader)\n",
    "    metrics = evaluator.state.metrics\n",
    "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
    "          .format(trainer.state.epoch, metrics[\"accuracy\"], metrics[\"nll\"]))\n",
    "\n",
    "\n",
    "trainer.run(data=my_train_loader, max_epochs=num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-13T07:40:18.751368Z",
     "start_time": "2020-07-13T07:32:26.317015Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/home/dev/installs/anaconda3/lib/python3.7/site-packages/ignite/metrics/accuracy.py\u001b[0m(58)\u001b[0;36m_check_binary_multilabel_cases\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     56 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     57 \u001b[0;31m        \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 58 \u001b[0;31m            \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"For binary cases, y_pred must be comprised of 0's and 1's.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     59 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     60 \u001b[0;31m    \u001b[0;32mdef\u001b[0m \u001b[0m_check_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSequence\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> y_pred[0][0]\n",
      "tensor([-0.0664, -0.0387,  0.0736, -0.1159,  0.0422, -0.0435,  0.0536,  0.0421,\n",
      "        -0.0714, -0.0342])\n",
      "ipdb> y[0][0]\n",
      "tensor(0., dtype=torch.float64)\n",
      "ipdb> y[0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=torch.float64)\n",
      "ipdb> y[0]\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 1., 0., 0.], dtype=torch.float64)\n",
      "ipdb> y_preds[0]\n",
      "*** NameError: name 'y_preds' is not defined\n",
      "ipdb> y_pred[0]\n",
      "tensor([[-0.0664, -0.0387,  0.0736, -0.1159,  0.0422, -0.0435,  0.0536,  0.0421,\n",
      "         -0.0714, -0.0342]])\n",
      "ipdb> quit()\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6sNoppkeNoz_"
   },
   "source": [
    "Our accuracy is much better than a random guess, however, we want to improve it!\n",
    "\n",
    "In order to improve our model preformence we should check whether our model overfits the data or try different hyper-parmeters.\n",
    "\n",
    "In order to check if our model overfits the data we can plot the loss of the training and the validation as function of the epoch number.\n",
    "We will not get into it now, but you will do it in your next exercices!\n",
    "\n",
    "So, now we will try different hyper-parameters in order to achieve better preformance.\n",
    "However, training took too much time! We must use our resources wisely!\n",
    "In the next chapter we will learn how to use the gpu!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ql8lYhQbP4L6"
   },
   "source": [
    "## Using the GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tNM-yUGYZMzI"
   },
   "source": [
    "By default all tensors are created on the CPU,\n",
    "but you can also move them to the GPU (if it's available)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:45:27.484967Z",
     "start_time": "2020-07-09T06:45:27.480669Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "4mxvlKWFP4aW",
    "outputId": "d3edb219-76bd-4d3b-9e16-fc2fcf0c1903"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NzXMzvSbapzb"
   },
   "source": [
    "You can directly create a tensor on GPU:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 363,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:45:41.932100Z",
     "start_time": "2020-07-09T06:45:41.926108Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "id": "35NiTndkZ95P",
    "outputId": "5e54a6c8-cb9c-437b-c765-04d6d4902895"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7509, 0.6720, 0.6881],\n",
      "        [0.6367, 0.4973, 0.9553],\n",
      "        [0.8852, 0.1407, 0.2076],\n",
      "        [0.8921, 0.9662, 0.7724],\n",
      "        [0.3806, 0.6426, 0.2970]]) \n",
      "\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(5,3) \n",
    "print(x, \"\\n\")\n",
    "y = torch.ones_like(x, device=device)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qno4hdqla014"
   },
   "source": [
    "Or you can just move it to the GPU. \n",
    "\n",
    "Additional option to indicate device is to use strings ``.to(\"cuda\")``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:45:46.280276Z",
     "start_time": "2020-07-09T06:45:46.276140Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "bpVBH4s9Z-CO",
    "outputId": "9fe2d373-5ecb-4ddc-f646-3dfdc0b871b9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7509, 0.6720, 0.6881],\n",
      "        [0.6367, 0.4973, 0.9553],\n",
      "        [0.8852, 0.1407, 0.2076],\n",
      "        [0.8921, 0.9662, 0.7724],\n",
      "        [0.3806, 0.6426, 0.2970]])\n"
     ]
    }
   ],
   "source": [
    "x = x.to(device)\n",
    "print(x)                      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-JVsJlffbO2g"
   },
   "source": [
    "It's not possible to convert tensor which is on the GPU to a numpy array because numpy cannot handle GPU tenors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:46:58.072524Z",
     "start_time": "2020-07-09T06:46:58.068008Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 292
    },
    "colab_type": "code",
    "id": "3UHHQDBkbDwX",
    "outputId": "cd6ee01f-29d6-4453-f1e7-f72300d0a404"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.7509, 1.6720, 1.6881],\n",
      "        [1.6367, 1.4973, 1.9553],\n",
      "        [1.8852, 1.1407, 1.2076],\n",
      "        [1.8921, 1.9662, 1.7724],\n",
      "        [1.3806, 1.6426, 1.2970]])\n"
     ]
    }
   ],
   "source": [
    "z = x + y\n",
    "print(z)\n",
    "z = z.numpy() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "M89kdQ1vcTzl"
   },
   "source": [
    "You have to move the tensor to the CPU and then convert it to a numpy array.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-09T06:47:18.826101Z",
     "start_time": "2020-07-09T06:47:18.822213Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105
    },
    "colab_type": "code",
    "id": "mURj8_DcbL9Z",
    "outputId": "8b37e8c5-8c7e-4be7-d1a2-64f2dd0e717f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.7509294 1.6720322 1.6880555]\n",
      " [1.6366901 1.4972756 1.9553366]\n",
      " [1.8851676 1.1407079 1.2075648]\n",
      " [1.8921181 1.9661878 1.7724428]\n",
      " [1.3805716 1.6426449 1.2970309]]\n"
     ]
    }
   ],
   "source": [
    "z = z.to(\"cpu\")       \n",
    "z = z.numpy()\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tl_9etX3nR9K"
   },
   "source": [
    "Now, after you have learnt how to run tensors on the GPU let's try it!\n",
    "\n",
    "✍️ Try to run your model from the previous chapter on the GPU.\n",
    "In order to make it you have to move any inputs/tensors and your model to the GPU.\n",
    "\n",
    "Did your time performance got better?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZEKIgsEAvST-"
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "Probably, your answer is no.\n",
    "\n",
    "This can happen when the cost of transferring data between RAM and GPU memory is more than the speedup of parallel computation on the GPU.\n",
    "\n",
    "It can happen when your model is quite small, or in case when you have too many transfers of data in your forward() function.\n",
    "\n",
    "If you still want to see improvment in the time preformance, increase the number of epochs and use only 1 batch (batch = all your dataset) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1sE06VviAKiR"
   },
   "source": [
    "## RNNs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OQljClGBJjZj"
   },
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "ChzhDpPPZwZ1",
    "y0yYyIDi-DVy",
    "maZnGuwo-bEu",
    "ZOMMiUS8-iTA",
    "c592nR1__vsZ",
    "9lWfOt4J_3Va",
    "rWwEpMST_7c6"
   ],
   "name": "Pytorch Tutorial.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "058ddde9299f4ad48eb342d6c9ebf8e5": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1948a4f92b834db3a2815fa21f42d09e",
       "IPY_MODEL_563eee532e3c42a692c7982427b86b45"
      ],
      "layout": "IPY_MODEL_df392a622edf4fddbc3a191df64e0716"
     }
    },
    "13ee488ac87d4ca08ca65c52007b9a45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_db1a520d33ec492cafc7c4bef5ac0b4d",
       "IPY_MODEL_e61e6d62807a4d98aa02ec9efce34385"
      ],
      "layout": "IPY_MODEL_13fb20cbc4ec498cb3647cb8bc5636e6"
     }
    },
    "13fb20cbc4ec498cb3647cb8bc5636e6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1948a4f92b834db3a2815fa21f42d09e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f7761dd859d44fbbb49e0e42ca1ee8a8",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c623591cb7a14d1eacaedf0e448d0dcb",
      "value": 1
     }
    },
    "1a1a983a94054905bb11a17b63849a42": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "1e316fe196364204a40b6086aa138042": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "374216a3626e44b6aaa31635e7e4463f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c719772f047d4b7dafc1d70a5d24b3f7",
      "placeholder": "​",
      "style": "IPY_MODEL_e7745844a9d74fd5a9f081921359e78d",
      "value": " 0/28881 [00:00&lt;?, ?it/s]"
     }
    },
    "3cf21db7920442a9b00e9fc29b080a7f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "55b895b1eb4540b3b85657182e7b2d3d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "563eee532e3c42a692c7982427b86b45": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3cf21db7920442a9b00e9fc29b080a7f",
      "placeholder": "​",
      "style": "IPY_MODEL_e22d257c1f9f441c85ac955e45747e94",
      "value": " 1654784/? [00:18&lt;00:00, 251485.57it/s]"
     }
    },
    "612439a0c2a74fac89324226f1d7ff33": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7be10f41d44a494d9f7b505defdddecd": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "8468b21b37584ea6a88794352c548154": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "905c9c03e2fb4e578b485676729e8a74": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dd1aadb71d6a4025aa1c3c5ef939a66e",
      "placeholder": "​",
      "style": "IPY_MODEL_f4aa2f9b38274399b79e1cde38002e5a",
      "value": " 0/4542 [00:00&lt;?, ?it/s]"
     }
    },
    "ba16954260ee49d186433e63b60f3757": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cb166b52b45f40188d4ff158ff1e9ff4",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_8468b21b37584ea6a88794352c548154",
      "value": 0
     }
    },
    "bf5a42a74d2649819101e76e175be5b0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "  0%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55b895b1eb4540b3b85657182e7b2d3d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c6d6eb302b6641639f9e23d1c85e718b",
      "value": 0
     }
    },
    "c3f755f2031140a58703ca96f2aba0c1": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c619812fdeb640809c699c56b87198f6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_ba16954260ee49d186433e63b60f3757",
       "IPY_MODEL_905c9c03e2fb4e578b485676729e8a74"
      ],
      "layout": "IPY_MODEL_612439a0c2a74fac89324226f1d7ff33"
     }
    },
    "c622970aa21d4950a22211d471ab0c37": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c623591cb7a14d1eacaedf0e448d0dcb": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c6526d53f38f4e18a2f05d10ed235b71": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_bf5a42a74d2649819101e76e175be5b0",
       "IPY_MODEL_374216a3626e44b6aaa31635e7e4463f"
      ],
      "layout": "IPY_MODEL_1e316fe196364204a40b6086aa138042"
     }
    },
    "c6d6eb302b6641639f9e23d1c85e718b": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "c719772f047d4b7dafc1d70a5d24b3f7": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "cb166b52b45f40188d4ff158ff1e9ff4": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "db1a520d33ec492cafc7c4bef5ac0b4d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7be10f41d44a494d9f7b505defdddecd",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_1a1a983a94054905bb11a17b63849a42",
      "value": 1
     }
    },
    "dd1aadb71d6a4025aa1c3c5ef939a66e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "df392a622edf4fddbc3a191df64e0716": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e22d257c1f9f441c85ac955e45747e94": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e61e6d62807a4d98aa02ec9efce34385": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c622970aa21d4950a22211d471ab0c37",
      "placeholder": "​",
      "style": "IPY_MODEL_c3f755f2031140a58703ca96f2aba0c1",
      "value": " 9920512/? [00:01&lt;00:00, 6100506.18it/s]"
     }
    },
    "e7745844a9d74fd5a9f081921359e78d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f4aa2f9b38274399b79e1cde38002e5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f7761dd859d44fbbb49e0e42ca1ee8a8": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
